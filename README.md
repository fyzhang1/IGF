# Gradient-Inversion-Attacks-in-Federated-Unlearning
Gradient Inversion Attacks in Federated Unlearning

## 1.generate the federared model

```fed_vison.ipynb```

## 2.import the model generated by the fed to test.py
```python test.py --lr 1e-4 --epochs 28 --leak_mode none --model MLP-6000 --dataset CIFAR10 --batch_size 256 --shared_model LeNet```